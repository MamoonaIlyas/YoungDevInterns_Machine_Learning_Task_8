import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

# Load dataset
df = pd.read_csv(r'D:\studies\Mamoona\AI&ML_Intern\preprocessed_cereal.csv')

# Create classification target
bins = [0, 40, 70, 100]
labels = ['Low', 'Medium', 'High']
df['rating_class'] = pd.cut(df['rating'], bins=bins, labels=labels)
df.drop(columns='rating', inplace=True)

# Features and labels
X = df.drop(columns='rating_class')
y = df['rating_class']

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42
)

# Define model
model = LogisticRegression(max_iter=1000)

# Clean param grid (removed multi_class, and only valid solvers)
param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'solver': ['lbfgs', 'newton-cg', 'sag'],
    'penalty': ['l2']
}

# Grid Search
grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=3,
    scoring='f1_macro',
    n_jobs=-1,
    verbose=1
)

# Fit model
grid_search.fit(X_train, y_train)

# Results
print("Best Hyperparameters:", grid_search.best_params_)
print("Best F1-macro Score (CV):", grid_search.best_score_)

# Evaluate on test set
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# Classification Report
target_names = ['High', 'Low', 'Medium']
report = classification_report(
    y_test, y_pred,
    labels=[0, 1, 2],
    target_names=target_names,
    zero_division=0
)
print("\n=== Classification Report ===")
print(report)
